{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent PoC\n",
    "\n",
    "This notebook tests how an AI agent can perform tasks and augment its knowledge by using a tools construct to call python methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading My AI Agent Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "list_dir = os.listdir(src_path)\n",
    "sys.path.append(src_path)\n",
    "from aiagent import AIAgent\n",
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "agent = AIAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Retrieval Process\n",
      "\n",
      "## System Prompt \n",
      "You are a preparing the data retrieval for a helpful assistant. \n",
      "You are getting a user request that the helpful assistant will need to answer.\n",
      "You are getting a list of tools that you can use to perform tasks and to receive external data to augment your knowledge if needed.\n",
      "You will analyze the user's request and respond nothing but a JSON object containing:\n",
      "    * the tool calls and their parameters\n",
      "    * A description of a plan how you will proceed after you received the results from the tools\n",
      "Here is the JSON schema for your response:\n",
      "```json\n",
      "{'$schema': 'https://json-schema.org/draft/2020-12/schema', 'type': 'object', 'required': ['tool_calls', 'plan'], 'properties': {'tool_calls': {'type': 'array', 'items': {'type': 'object', 'required': ['tool', 'parameters'], 'properties': {'tool': {'type': 'string'}, 'parameters': {'type': 'object', 'additionalProperties': {'type': 'string'}}}}}, 'plan': {'type': 'string'}}}\n",
      "```    \n",
      "\n",
      "## User request\n",
      "I will now start a two hour ride. At what time will I arrive?\n",
      "\n",
      "\n",
      "## Available tools API specs\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"time\",\n",
      "        \"description\": \"Get the current time\",\n",
      "        \"parameters\": [\n",
      "            {}\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"search\",\n",
      "        \"description\": \"Search the web\",\n",
      "        \"parameters\": [\n",
      "            {\n",
      "                \"name\": \"query\",\n",
      "                \"type\": \"str\",\n",
      "                \"description\": \"The search query\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "```\n",
      "You shall only use the tools provided, do not invent new tools.\n",
      "\n",
      "## Example\n",
      "For a user question like \"Summarize the latest news for me\", the expected example JSON response:\n",
      "```json\n",
      "{\n",
      "    \n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"tool\": \"search\",\n",
      "            \"parameters\": {\n",
      "                \"query\": \"news\"\n",
      "            }\n",
      "        },\n",
      "    ],\n",
      "    \"plan\": \"I will summarize the news based on the search results.\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_request = \"I will now start a two hour ride. At what time will I arrive?\"\n",
    "retrieval_prompt = agent.get_retrieval_prompt(user_request)\n",
    "print(retrieval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Your response\n",
      "\n",
      "Here is my JSON response:\n",
      "```json\n",
      "{\n",
      "    \"tool_calls\": [\n",
      "        {\n",
      "            \"tool\": \"time\",\n",
      "            \"parameters\": {}\n",
      "        },\n",
      "        {\n",
      "            \"tool\": \"search\",\n",
      "            \"parameters\": {\n",
      "                \"query\": \"traffic\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"plan\": \"I will use the current time and search results to estimate when I'll arrive.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#with model.chat_session():\n",
    "#    response = model.generate(retrieval_prompt, max_tokens=1024)\n",
    "response = model.generate(retrieval_prompt, max_tokens=1024)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_calls': [{'tool': 'time', 'parameters': {}, 'response': '2025-02-26 23:35:11'}, {'tool': 'search', 'parameters': {'query': 'traffic'}, 'response': 'Searching the web for: traffic'}], 'plan': \"I will use the current time and search results to estimate when I'll arrive.\"}\n"
     ]
    }
   ],
   "source": [
    "processed_response = agent.process_response(response)\n",
    "print(processed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "## Interpretation Process\n",
      "\n",
      "### Step 1: Understand the user request\n",
      "The user wants to know at what time they will arrive after a two-hour ride.\n",
      "\n",
      "### Step 2: Review the retrieval process results\n",
      "I have received the results of the retrieval process, which include:\n",
      "\n",
      "* Tool calls:\n",
      "\t+ A call to `time` tool with no parameters and response '2025-02-26 23:35:11' (current time).\n",
      "\t+ A call to `search` tool with query parameter set to `'traffic'` and response is a search result.\n",
      "* Plan: Use the current time and search results to estimate when I'll arrive.\n",
      "\n",
      "### Step 3: Analyze the information\n",
      "To answer the user's question, I need to analyze the information from the retrieval process. The `time` tool call provides me with the current time (`2025-02-26 23:35:11`). The `search` tool call gives me a search result related to traffic.\n",
      "\n",
      "### Step 4: Make an educated guess\n",
      "Based on my analysis, I can make an educated guess about when the user will arrive. Since they are starting their ride at this moment (`2025-02-26 23:35:11`) and it's going to take them two hours to complete the ride, I estimate that they will arrive at `2025-02-27 01:35:11`.\n",
      "\n",
      "### Step 5: Provide a response\n",
      "Here is my response:\n",
      "\n",
      "\"Based on your current location (`2025-02-26 23:35:11`) and assuming it takes you two hours to complete the ride, I estimate that you will arrive at `2025-02-27 01:35:11`. Please note that this estimation may vary depending on traffic conditions.\"\n",
      "\n",
      "\n",
      "\n",
      "## Final Response\n",
      "\"Based on your current location (`2025-02-26 23:35:11`) and assuming it takes you two hours to complete the ride, I estimate that you will arrive at `2025-02-27 01:35:11`. Please note that this estimation may vary depending on traffic conditions.\"\n"
     ]
    }
   ],
   "source": [
    "interpretation_prompt = agent.get_interpretation_prompt(user_request, processed_response)\n",
    "interpretation = model.generate(interpretation_prompt, max_tokens=1024)\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
