{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent PoC\n",
    "\n",
    "This notebook tests how an AI agent can perform tasks and augment its knowledge by using a tools construct to call python methods.\n",
    "\n",
    "How it works:\n",
    "1. It takes a user requests and embeds the request into a \"retrieval prompt\". The prompt contains instructions that help the LLM model to respond in a structured way with a list of tasks, needed to fulfill the users request.\n",
    "2. The LLMs resonse is getting parsed and interpreted by the AIAgent. The AIAgent will perform the requested tasks.\n",
    "3. The outcome of the tasks is used to generate a \"interpretation prompt\" to allow the LLM to complete the user's request. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading My AI Agent Lib\n",
    "\n",
    "* The example uses the GPT4All lib which will download the specified LLM model (the first run takes a bit time)\n",
    "* The example uses some Python code, which is located in the `../src`folder. The folder gets added to the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from gpt4all import GPT4All\n",
    "from IPython.display import Markdown, JSON, display    \n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "list_dir = os.listdir(src_path)\n",
    "sys.path.append(src_path)\n",
    "from aiagent import AIAgent\n",
    "\n",
    "model = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "agent = AIAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate The Retrieval Prompt\n",
    "\n",
    "* Definition of the user request in the `user_request`variable\n",
    "* Generating the retrieval prompt. The retrieval prompt is formatted in Markdown\n",
    "* displaying the retrieval prompt, rendered as Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## System Prompt \n",
       "You are a preparing the data retrieval for a helpful assistant. \n",
       "You are getting a user request that the helpful assistant will need to answer.\n",
       "You are getting a list of tools that you can use to perform tasks and to receive external data to augment your knowledge if needed.\n",
       "You will analyze the user's request and respond nothing but a JSON object containing:\n",
       "\n",
       "  * the tool calls and their parameters\n",
       "  * A description of a plan how you will proceed after you received the results from the tools\n",
       "\n",
       "### Here is the JSON schema for your response:\n",
       "```json\n",
       "{\n",
       "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
       "    \"type\": \"object\",\n",
       "    \"required\": [\n",
       "        \"tool_calls\",\n",
       "        \"plan\"\n",
       "    ],\n",
       "    \"properties\": {\n",
       "        \"tool_calls\": {\n",
       "            \"type\": \"array\",\n",
       "            \"items\": {\n",
       "                \"type\": \"object\",\n",
       "                \"required\": [\n",
       "                    \"tool\",\n",
       "                    \"parameters\"\n",
       "                ],\n",
       "                \"properties\": {\n",
       "                    \"tool\": {\n",
       "                        \"type\": \"string\"\n",
       "                    },\n",
       "                    \"parameters\": {\n",
       "                        \"type\": \"object\",\n",
       "                        \"additionalProperties\": {\n",
       "                            \"type\": \"string\"\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "        },\n",
       "        \"plan\": {\n",
       "            \"type\": \"string\"\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```    \n",
       "\n",
       "### Available tools API specs\n",
       "```json\n",
       "[\n",
       "    {\n",
       "        \"name\": \"time\",\n",
       "        \"description\": \"Get the current time\",\n",
       "        \"parameters\": [\n",
       "            {}\n",
       "        ]\n",
       "    },\n",
       "    {\n",
       "        \"name\": \"search\",\n",
       "        \"description\": \"Search the web\",\n",
       "        \"parameters\": [\n",
       "            {\n",
       "                \"name\": \"query\",\n",
       "                \"type\": \"str\",\n",
       "                \"description\": \"The search query\"\n",
       "            }\n",
       "        ]\n",
       "    }\n",
       "]\n",
       "```\n",
       "You shall only use the tools provided, do not invent new tools.\n",
       "\n",
       "### Example\n",
       "For a user question like \"Summarize the latest news for me\", the expected example JSON response:\n",
       "```json\n",
       "{\n",
       "    \n",
       "    \"tool_calls\": [\n",
       "        {\n",
       "            \"tool\": \"search\",\n",
       "            \"parameters\": {\n",
       "                \"query\": \"news\"\n",
       "            }\n",
       "        },\n",
       "    ],\n",
       "    \"plan\": \"I will summarize the news based on the search results.\"\n",
       "}\n",
       "```\n",
       "\n",
       "## User Prompt\n",
       "I will now start a two hour ride. At what time will I arrive?\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_request = \"I will now start a two hour ride. At what time will I arrive?\"\n",
    "retrieval_prompt = agent.get_retrieval_prompt(user_request)\n",
    "\n",
    "display(Markdown(retrieval_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feed Prompt to LLM\n",
    "\n",
    "* feed the prompt to the LLM and print the response (takes some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Your JSON response should look like this:\n",
       "```json\n",
       "{    \n",
       "    \"tool_calls\": [\n",
       "        {\n",
       "            \"tool\": \"time\",\n",
       "            \"parameters\": {}\n",
       "        }\n",
       "    ],\n",
       "    \"plan\": \"After receiving the current time, I will calculate when you will arrive based on a two hour ride.\"\n",
       "}\n",
       "```\n",
       "Please provide your JSON response."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#with model.chat_session():\n",
    "#    response = model.generate(retrieval_prompt, max_tokens=1024)\n",
    "retrieval_response = model.generate(retrieval_prompt, max_tokens=1024)\n",
    "display(Markdown(retrieval_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Response Parsing & Processing\n",
    "\n",
    "* Extract JSON structure from response\n",
    "* Run the requested tools\n",
    "* Add response to JSON structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```json\n",
       "{\n",
       "    \"tool_calls\": [\n",
       "        {\n",
       "            \"tool\": \"time\",\n",
       "            \"parameters\": {},\n",
       "            \"response\": \"2025-02-27 15:22:23\"\n",
       "        }\n",
       "    ],\n",
       "    \"plan\": \"I will use the current time to calculate when I will arrive after a two hour ride.\"\n",
       "}\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_response = agent.process_response(retrieval_response)\n",
    "formatted_json = json.dumps(processed_response, indent=4)\n",
    "formatted_json_md =f\"\"\"\n",
    "```json\n",
    "{formatted_json}\n",
    "```\n",
    "\"\"\"\n",
    "display(Markdown(formatted_json_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Interpretation Prompt\n",
    "\n",
    "* Generating the interpretation prompt, asking the LLM to conclude on the user request based tasks performed and the augmented information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## System Prompt\n",
       "You are a helpful assistant. \n",
       "You are getting a user request that the you want to answer.\n",
       "As preparation a retrieval process has been done to augment you with additional input.\n",
       "You are expected to interpret the results and provide a response to the user.\n",
       "\n",
       "## User Prompt\n",
       "I will now start a two hour ride. At what time will I arrive?\n",
       "\n",
       "### Results of the retrieval process\n",
       "```json\n",
       "{\n",
       "    \"tool_calls\": [\n",
       "        {\n",
       "            \"tool\": \"time\",\n",
       "            \"parameters\": {},\n",
       "            \"response\": \"2025-02-27 15:22:23\"\n",
       "        }\n",
       "    ],\n",
       "    \"plan\": \"I will use the current time to calculate when I will arrive after a two hour ride.\"\n",
       "}\n",
       "```\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpretation_prompt = agent.get_interpretation_prompt(user_request, processed_response)\n",
    "display(Markdown(interpretation_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feed Prompt to LLM\n",
    "\n",
    "* feed the prompt to the LLM and print the response (takes some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\n",
       "\n",
       "## Interpretation Process\n",
       "\n",
       "1. Identify the relevant information from the results of the retrieval process:\n",
       "   - The tool used is 'time'.\n",
       "   - There are no parameters provided.\n",
       "   - The response is in the format 'YYYY-MM-DD HH:MM:SS', which represents a date and time.\n",
       "\n",
       "2. Understand the user request:\n",
       "   - The user wants to know at what time they will arrive after a two hour ride, starting from now.\n",
       "\n",
       "3. Calculate the arrival time based on the current time and the duration of the ride (two hours):\n",
       "   - Get the current time using the 'time' tool.\n",
       "   - Add two hours to the current time to get the expected arrival time.\n",
       "\n",
       "4. Format the response:\n",
       "   - Use the format provided in the results ('YYYY-MM-DD HH:MM:SS') to display the calculated arrival time.\n",
       "\n",
       "5. Provide a response to the user:\n",
       "   - \"You will arrive at 2025-02-27 17:22:23.\"\n",
       "\n",
       "\n",
       "\n",
       "## Final Response\n",
       "You will arrive at 2025-02-27 17:22:23."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpretation = model.generate(interpretation_prompt, max_tokens=1024)\n",
    "display(Markdown(interpretation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
